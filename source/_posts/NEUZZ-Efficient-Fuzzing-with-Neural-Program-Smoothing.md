---
title: 'NEUZZ: Efficient Fuzzing with Neural Program Smoothing'
date: 2019-04-11 21:05:03
tags:
categories:
---

# Abstract

Fuzzing已经成为发现软件漏洞的事实上的标准技术。然而，即使是最先进的模糊器也不能很有效地找到难以触发的软件错误。最流行的模糊器使用进化指导来生成可以触发不同错误的输入。这种进化算法虽然快速且易于实现，但常常陷入无效的随机突变序列中。梯度引导优化是进化指导的有前途的替代方案。梯度引导技术已经被证明通过有效利用基础函数的梯度或高阶导数来解决机器学习等领域中的高维结构优化问题，从而显着优于进化算法。
然而，梯度引导方法不能直接应用于模糊测试，因为真实世界的程序行为包含许多不连续性，平台和脊，其中基于梯度的方法经常被卡住。我们观察到这个问题可以通过创建一个近似于目标程序的离散分支行为的平滑代理函数来解决。
在本文中，我们提出了一种新的程序平滑技术，使用替代神经网络模型，可以逐步学习复杂的，真实世界的程序的分支行为的平滑近似。我们进一步证明，这种神经网络模型可以与梯度引导输入生成方案一起使用，以显着提高模糊测试过程的效率。
我们的广泛评估表明，NEUZZ在发现新漏洞和实现更高边缘覆盖率方面，在10个流行的真实世界节目中明显优于10个最先进的灰盒模糊器。 NEUZZ发现31个先前未知的错误（包括两个CVE），其他模糊测试器在10个真实世界的程序中找不到，并且比24小时运行的所有测试的灰盒模糊器实现了3倍的边缘覆盖。此外，NEUZZ在LAVA-M和DARPA CGC bug数据集上也优于现有的模糊器。



| relevant information |      |
| -------------------- | ---- |
| *作者*               |      |
| *单位*               |      |
| *出处*               |      |
| *原文地址*           |      |
| *源码地址*           |      |
| *发表时间*           |      |

# 1. 简介

模糊测试已成为发现软件漏洞的事实上的标准技术[88]，[25]。模糊测试过程涉及生成随机测试输入并使用这些输入执行目标程序以触发潜在的安全漏洞[59]。由于其简单性和低性能开销，在许多真实世界的程序中，模糊测试在寻找不同类型的安全漏洞方面非常成功[3]，[1]，[30]，[70]，[11]，[78] 。尽管它们有巨大的希望，但流行的模糊测试器，特别是对于大型程序，往往会在尝试冗余测试输入时遇到困难，并且很难找到隐藏在程序逻辑深处的安全漏洞[82]，[36]，[68]。

从概念上讲，模糊测试是一个优化问题，其目标是找到程序输入，以最大化在给定量的测试时间内发现的漏洞数量[60]。然而，由于安全漏洞往往是稀疏且不规律地分布在程序中，因此大多数模糊测试器旨在通过最大化某种形式的代码覆盖（例如，边缘覆盖）来测试尽可能多的程序代码，以增加其发现安全漏洞的机会。最流行的模糊器使用进化算法来解决潜在的优化问题 - 生成最大化代码覆盖的新输入[88]，[11]，[78]，[45]。进化优化从一组种子输入开始，将随机突变应用于种子以生成新的测试输入，执行这些输入的目标程序，并且仅保留有希望的新输入（例如，那些实现新代码覆盖的输入）作为进一步突变的语料库。然而，随着输入语料库变大，进化过程在到达新代码位置时变得越来越低效。

进化优化算法的主要限制之一是它们不能利用底层优化问题的结构（即梯度或其他高阶导数）。梯度引导优化（例如，梯度下降）是一种很有前途的替代方法，已被证明在解决包括空气动力学计算和机器学习在内的各种领域中的高维结构优化问题时显着优于进化算法[89]，[46]，[ 38。

然而，梯度引导优化算法不能直接应用于模糊现实世界的程序，因为它们通常包含大量不连续行为（不能精确计算梯度的情况），因为不同程序分支的行为差别很大[67]，[ 21]，[43]，[20]，[22]。我们观察到可以通过创建近似于目标程序关于程序输入的分支行为的平滑（即，可微分）代理函数来克服该问题。不幸的是，现有的程序平滑技术[21]，[20]会产生令人望而却步的性能开销，因为它们严重依赖于符号分析，但是由于路径爆炸，不完整的环境建模和符号内存建模的大量开销等几个基本限制而无法扩展到大型程序50]，[77]，[14]，[16]，[15]，[35]，[49]。

在本文中，我们介绍了一种新颖，高效，可扩展的程序平滑技术，该技术使用前馈神经网络（NN），可以逐步学习复杂的，真实世界的程序分支行为的平滑近似，即预测控制流边缘。目标程序由特定的输入执行。我们进一步提出梯度引导搜索策略，其计算并利用平滑近似的梯度（即，NN模型）来识别目标突变位置，其可以最大化目标程序中检测到的错误的数量。我们演示了如何通过在错误预测的程序行为上逐步重新训练模型来改进NN模型。我们发现前馈神经网络是我们任务的自然拟合，因为（i）它们证明了近似复杂非线性函数的能力，如通用逼近定理[33]所暗示的，以及（ii）它们对有效和精确计算梯度/高阶导数[38]。

我们设计并实施了我们的技术，作为NEUZZ的一部分，NEUZZ是一种新的学习型模糊器。我们将NEUZZ与10个最先进的模糊器进行比较，包括6种不同的文件格式（例如，ELF，PDF，XML，ZIP，TTF和JPEG），平均为47.546行代码，LAVA-M bug数据集[28]和CGC数据集[26]。我们的结果表明，NEUZZ在检测到的错误和实现的边缘覆盖方面始终优于所有其他模糊器。 NEUZZ在其他模糊测试仪未能找到的测试程序中发现了31个以前未知的错误（包括CVE-2018-19931和CVE-2018-19932）。我们对DARPA CGC数据集的测试也证实，NEUZZ在发现不同的错误时可以胜过最先进的模糊器，如Driller [82]。

我们在本文中的主要贡献如下：

- 我们是第一个确定程序平滑的重要性，采用有效的梯度引导技术进行模糊测试。
- 我们引入了第一个使用替代神经网络的高效且可扩展的程序平滑技术，以有效地模拟目标程序的分支行为。我们进一步提出了一种增量学习技术，以在更多训练数据可用时迭代地改进替代模型。
- 我们证明了替代神经网络模型的梯度可用于有效地生成程序输入，从而最大化目标程序中发现的错误数量。
- 我们作为NEUZZ的一部分设计，实施和评估我们的技术，并证明它在各种实际程序以及策划的bug数据集上明显优于10个最先进的模糊器。

本文的其余部分安排如下。第二部分总结了有关优化和梯度引导技术的必要背景信息。第三部分概述了我们的技术以及一个激励性的例子。第IV节和第V节详细描述了我们的方法和实施。我们在第VI节中介绍了我们的实验结果，并描述了NEUZZ在第VII节中发现的一些样本错误。第八节总结了相关工作，第九节总结了论文

# II.优化基础

在本节中，我们首先描述优化的基础知识以及梯度引导优化相对于平滑函数的进化指导的益处。最后，我们演示了如何将模糊测试作为优化问题。

优化问题通常由三个不同的组件组成：参数x的向量，要最小化或最大化的目标函数F（x），以及一组约束函数Ci（x），每个约束函数包括必须满足的不等式或相等性。优化过程的目标是找到参数向量x的具体值，其最大化/最小化F（x），同时满足所有约束函数Ci（x），如下所示。

![](NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/1.jpg)

这里R，N和Q分别表示实数集，不等式约束指数和等式约束指数

**函数平滑和优化。**优化算法通常在循环中操作，从对参数向量x的初始猜测开始，并逐渐迭代以找到更好的解。任何优化算法的关键组件是它用于从一个x值移动到下一个值的策略。大多数策略利用目标函数F，约束函数Ci以及梯度/高阶导数（如果可用）的值。

不同优化算法收敛到最优解的能力和效率在很大程度上取决于目标和约束函数F和Ci的性质。通常，可以比具有许多不连续性（例如，脊或平台）的函数更有效地优化更平滑的函数（即，具有明确定义和可计算的导数的函数）。直观地，目标/约束函数越平滑，优化算法就越容易准确地计算梯度或高阶导数，并使用它们系统地搜索整个参数空间。

对于本文的其余部分，我们特别关注不具有任何约束函数的无约束优化问题，即C =φ，因为它们非常模仿模糊化，即我们的目标域。对于无约束平滑优化问题，梯度引导方法在解决高维结构优化问题时可以明显优于进化策略[89]，[46]，[38]。这是因为梯度引导技术有效地利用梯度/高阶导数有效地收敛到最优解，如图1所示。

![](NEUZZ-Efficient-Fuzzing-with-Neural-Program-Smoothing/2.jpg)

**凸度和梯度引导优化。**对于称为凸函数的常见函数类，梯度引导技术非常高效，并且总能收敛到全局最优解[86]。直观地，如果连接函数图上任意两点的直线完全位于图上方或上方，则函数是凸的。
更正式地，如果在其域中的所有点x和y满足以下属性，则函数f被称为凸函数：f（tx +（1-t）y）≤ tf（x）+（1-t）f （y）,存在 t 属于[0; 1]。

然而，在非凸函数中，梯度引导方法可能会陷入局部最优解，其中目标函数（假设目标是最大化）比所有附近的可行点更大但是在整个其他地方存在其他更大的值可行参数值的范围。然而，即使对于这种情况，简单的启发式方法，例如从新的随机选择的起始点重新启动梯度引导方法，已经证明在实践中非常有效[38]，[86]。

**模糊作为无约束的优化。**模糊测试可以表示为无约束优化问题，其目标是最大化测试程序中针对固定数量的测试输入发现的错误/漏洞的数量。因此，目标函数可以被认为是F_p（x），如果输入x在使用输入x执行目标程序p时触发错误/漏洞，则返回1。然而，这种函数太不正常（即，主要包含平坦的平台和一些非常尖锐的过渡）以便有效地优化。

因此，大多数灰盒模糊器试图最大化测试代码的数量（例如，最大化边缘覆盖）作为替代代理度量[88]，[11]，[73]，[55]，[22]。这样的目标函数可以表示为F’_p（x），其中F’返回程序P的输入x所覆盖的新控制流边缘的数量。注意，F比原始函数F相对更容易优化。所有可能的程序输入执行新的控制流边缘往往明显高于触发错误/安全漏洞的输入。

大多数现有的灰盒模糊器使用进化技术[88]，[11]，[73]，[55]，[22]以及其他特定领域的启发式算法作为其主要的优化策略。在梯度引导优化中选择此类算法的关键原因是大多数真实世界的程序由于沿着不同程序路径的显着不同的行为而包含许多不连续性[19]。这种不连续性可能导致梯度引导优化陷入非最优解。在本文中，我们提出了一种新技术，使用神经网络平滑目标程序，使其适用于梯度引导优化，并演示模糊器如何利用这些策略来显着提高其效率。

